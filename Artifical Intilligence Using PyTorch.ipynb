{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "onM3Tm0D_O_N"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Artifical Intilligence \n",
        "#Chen Zakaim , id: 313303422\n",
        "#Ilor Rot , id: 208916189"
      ],
      "metadata": {
        "id": "6zAvE_iQavZy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#packs"
      ],
      "metadata": {
        "id": "0SShatk57Whd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDeJvjpjrWyt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "bc=datasets.load_breast_cancer()\n",
        "import time\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import KFold\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ITt0aVSgqynu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparing the datasets"
      ],
      "metadata": {
        "id": "O2fTevhm8fxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X,y= bc.data ,bc.target\n",
        "df = pd.DataFrame(data=bc.data, columns=bc.feature_names)\n",
        "df2 = df.assign(target=bc.target)\n",
        "X=df2.iloc[0:569,0:30]\n",
        "Y=df2['target']\n",
        "importances = mutual_info_classif(X, Y)\n",
        "feat_importances=pd.Series(importances,df2.columns[0:len(df2.columns)-1]) \n",
        "feat_importances.plot(kind='barh')\n",
        "plt.title(\"Feature Importence\")\n",
        "plt.show()\n",
        "bc=df.drop([\"worst fractal dimension\", \"worst symmetry\",\"fractal dimension error\",\"symmetry error\",\"smoothness error\",\"mean texture\"], axis=1)\n",
        "#print(bc.head(6))\n",
        "X=bc.to_numpy()\n",
        "y=Y.to_numpy()\n"
      ],
      "metadata": {
        "cellView": "code",
        "id": "KbCiUaNTkxsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_sample,n_features=X.shape\n",
        "sc=StandardScaler()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
        "\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.fit_transform(X_test)\n",
        "X_val=sc.fit_transform(X_val)\n",
        "\n",
        "X_val=torch.from_numpy(X_val.astype(np.float32))\n",
        "X_train=torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test=torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train=torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test=torch.from_numpy(y_test.astype(np.float32))\n",
        "y_val=torch.from_numpy(y_val.astype(np.float32))\n",
        "\n",
        "y_train=y_train.view(y_train.shape[0],1)\n",
        "y_test=y_test.view(y_test.shape[0],1)\n",
        "y_val=y_val.view(y_val.shape[0],1)\n"
      ],
      "metadata": {
        "id": "JFo_ljObsysr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_val.shape)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "sMQWbW8G3-I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression"
      ],
      "metadata": {
        "id": "iPFZHXaSx0_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jsUSNejgGHQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "     def __init__(self, n_input_features):\n",
        "         super(LogisticRegression, self).__init__()\n",
        "         self.linear = torch.nn.Linear(n_input_features, 1)\n",
        "     def forward(self, x):\n",
        "       y_predicted= torch.sigmoid(self.linear(x))\n",
        "       return y_predicted  \n",
        "model=LogisticRegression(n_features)\n",
        "\n"
      ],
      "metadata": {
        "id": "4P7OA8WSHfPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "model = model.to(torch.device('cuda:0'))\n",
        "\n",
        "\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "start.record()\n",
        "\n",
        "iteration_number = 80000\n",
        "model=LogisticRegression(n_features)\n",
        "criterion=nn.BCELoss()\n",
        "learning_rate=0.23\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "\n",
        "#The validation Curve\n",
        "def val_curve():\n",
        "  loss_train = []\n",
        "  loss_val=[]\n",
        "  \n",
        "  for epoch in range(1, iteration_number+1):\n",
        "      \n",
        "      # Forward to get output\n",
        "      results = model(X_train)\n",
        "        \n",
        "        # Calculate Loss\n",
        "      loss = criterion(results, y_train)\n",
        "        \n",
        "        # backward propagation\n",
        "      loss.backward()\n",
        "        \n",
        "        # Updating parameters\n",
        "      optimizer.step()\n",
        "        \n",
        "        # optimization\n",
        "      optimizer.zero_grad() \n",
        "\n",
        "      # store loss\n",
        "      loss_train.append(loss.data)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        y_val_predictions = model(X_val)\n",
        "        y_val_predictions_classes = y_val_predictions.round()\n",
        "        loss_val.append(criterion(y_val_predictions,y_val))\n",
        "        # loss_val = 0\n",
        "\n",
        "  return loss_train, loss_val\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "alpha = np.linspace(1,iteration_number,iteration_number)\n",
        "loss_train, loss_val = val_curve()\n",
        "\n",
        "plt.plot(alpha, loss_train,label='Train Curve')\n",
        "plt.plot(alpha, loss_val,label='Validation Curve')\n",
        "\n",
        "plt.xlabel('number of iterations', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.legend()\n",
        "plt.title('Loss by iterations')\n",
        "plt.show()\n",
        "end.record()\n",
        "torch.cuda.synchronize()  # Waits for everything to finish running on the GPU\n",
        "print(f\"GPU time: {0.001 * start.elapsed_time(end):6.5f}s\")  # Milliseconds to seconds\n"
      ],
      "metadata": {
        "id": "LFxQRVKRnvSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, torch.tensor((model(X_test))))\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr, tpr, marker='.')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#finding the optimal threshold \n",
        "\n",
        "gmean = np.sqrt(tpr * (1 - fpr))\n",
        "index = np.argmax(gmean)\n",
        "thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "gmeanOpt = round(gmean[index], ndigits = 4)\n",
        "fprOpt = round(fpr[index], ndigits = 4)\n",
        "tprOpt = round(tpr[index], ndigits = 4)\n",
        "\n",
        "\n",
        "def convert_binary(set):\n",
        "  results=[]\n",
        "  for i in range(len(set)):\n",
        "    if set[i]>thresholdOpt:\n",
        "      results.append(1)\n",
        "    else:\n",
        "      results.append(0)\n",
        "  return results\n",
        "\n",
        "\n",
        "conf_matrix =confusion_matrix(y_test, convert_binary(model(X_test)))\n",
        "fig, ax = plt.subplots(figsize=(3, 3))\n",
        "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title('Confusion Matrix', fontsize=18)\n",
        "plt.show()\n",
        "\n",
        "end.record()\n",
        "torch.cuda.synchronize()  # Waits for everything to finish running on the GPU\n",
        "print(f\"GPU time: {0.001 * start.elapsed_time(end):6.5f}s\")  # Milliseconds to seconds\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lT-2-c7QGMgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#tuning learning rate of logistic regression"
      ],
      "metadata": {
        "id": "onM3Tm0D_O_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import random\n",
        "alpha=np.linspace(0.001,10,1000)\n",
        "rows_idxs = list(range(X_train.shape[0]))\n",
        "model=LogisticRegression(n_features)\n",
        "def rate_tune():\n",
        "  loss_history=[]\n",
        "  epochs=40\n",
        "  for learning_rate in alpha:\n",
        "    model=LogisticRegression(n_features)\n",
        "    optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "    for k in range(epochs):\n",
        "\n",
        "\n",
        "        y_train_pred_probablity = model(X_train)\n",
        "\n",
        "        # optimization\n",
        "        optimizer.zero_grad() \n",
        "      \n",
        "      # Forward to get output\n",
        "        results = model(X_train)\n",
        "      \n",
        "      # Calculate Loss\n",
        "        loss = criterion(y_train_pred_probablity, y_train)\n",
        "      \n",
        "      # backward propagation\n",
        "        loss.backward()\n",
        "      \n",
        "      # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "      # # store loss\n",
        "      # loss_history.append(loss.data)\n",
        "\n",
        "\n",
        "    y_val_pred_probablity = model(X_val)\n",
        "    loss_history.append(criterion(y_val_pred_probablity, y_val).item())\n",
        "  return loss_history\n",
        "\n",
        "rate_tune()\n",
        "plt.plot(alpha, rate_tune())\n",
        "plt.xlabel('Learning rates', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TcuHiTUilMS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X-Xm8Xan3iUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Networks"
      ],
      "metadata": {
        "id": "-YNqfXZfJKUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class neural_classification(nn.Module):\n",
        "  def __init__(self,input_size,hidden1_size,hidden2_size,num_classes):\n",
        "\n",
        "    super(neural_classification,self).__init__()\n",
        "    \n",
        "    self.fc1=nn.Linear(input_size,hidden1_size)\n",
        "\n",
        "    self.fc2=nn.Linear(hidden1_size,hidden2_size)\n",
        "\n",
        "    self.fc3=nn.Linear(hidden2_size,num_classes)\n",
        "    \n",
        "  def forward(self,x):\n",
        "\n",
        "\n",
        "      x= torch.relu(self.fc1(x))\n",
        "\n",
        "      x= torch.relu(self.fc2(x))\n",
        "\n",
        "      x=torch.sigmoid(self.fc3(x))\n",
        "\n",
        "      return x\n"
      ],
      "metadata": {
        "id": "rriSlvcOpI3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "model_NN=neural_classification(24,10,50,1)\n",
        "model_NN = model_NN.to(torch.device('cuda:0'))\n",
        "\n",
        "\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "start.record()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "learning_rate=0.1\n",
        "#I use binary cross entropy loss function because here we have a binary classification mission \n",
        "criterion=nn.BCELoss()\n",
        "optimizer=torch.optim.SGD(model_NN.parameters(),lr=learning_rate)\n",
        "\n",
        "  \n",
        "# train model\n",
        "loss_list = []\n",
        "iteration_number = 200\n",
        "for iteration in range(iteration_number):\n",
        "  y_prediction=model_NN(X_train.cuda())\n",
        "        \n",
        "    # optimization\n",
        "  optimizer.zero_grad() \n",
        "    \n",
        "    # Forward to get output\n",
        "  results = model_NN(X_train.cuda())\n",
        "    \n",
        "    # Calculate Loss\n",
        "  loss = criterion(y_prediction,y_train.cuda())\n",
        "    \n",
        "    # backward propagation\n",
        "  loss.backward()\n",
        "    \n",
        "    # Updating parameters\n",
        "  optimizer.step()\n",
        "    \n",
        "    # store loss\n",
        "  loss_list.append(loss.data)\n",
        "    \n",
        "    # print loss\n",
        "  if(iteration % 50 == 0):\n",
        "    print('epoch {}, loss {}'.format(iteration, loss.data))\n",
        "\n",
        "cpu_loss_list = torch.tensor(loss_list, device = 'cpu')\n",
        "plt.plot(range(iteration_number),cpu_loss_list)\n",
        "plt.title(\"Loss by iteration - NN\")\n",
        "plt.xlabel(\"Number of Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(torch.tensor(y_test, device = 'cpu'), torch.tensor(model_NN(X_test.cuda()), device = 'cpu'))\n",
        "\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'y--')\n",
        "plt.plot(fpr, tpr, marker='.')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "#finding the optimal threshold \n",
        "\n",
        "gmean = np.sqrt(tpr * (1 - fpr))\n",
        "index = np.argmax(gmean)\n",
        "thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "gmeanOpt = round(gmean[index], ndigits = 4)\n",
        "fprOpt = round(fpr[index], ndigits = 4)\n",
        "tprOpt = round(tpr[index], ndigits = 4)\n",
        "\n",
        "def convert_binary(set):\n",
        "  results=[]\n",
        "  for i in range(len(set)):\n",
        "    if set[i]>thresholdOpt:\n",
        "      results.append(1)\n",
        "    else:\n",
        "      results.append(0)\n",
        "  return results\n",
        "\n",
        "conf_matrix =confusion_matrix(torch.tensor(y_test, device = 'cpu'), torch.tensor(convert_binary(model_NN(X_test.cuda())), device = 'cpu'))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(3, 3))\n",
        "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Zi4nzMjiNBff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loss_list[0].cpu()\n"
      ],
      "metadata": {
        "id": "efutqTGyCQIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.cuba"
      ],
      "metadata": {
        "id": "ULtEdVTHEVcp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}